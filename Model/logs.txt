Using TensorFlow backend.
(61035, 1025)
(54931, 32, 32, 1) (54931, 27)
(6104, 32, 32, 1) (6104, 27)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       
_________________________________________________________________
activation_1 (Activation)    (None, 28, 28, 32)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         
_________________________________________________________________
activation_2 (Activation)    (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 12, 12, 16)        4624      
_________________________________________________________________
activation_3 (Activation)    (None, 12, 12, 16)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 10, 10, 8)         1160      
_________________________________________________________________
activation_4 (Activation)    (None, 10, 10, 8)         0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 5, 5, 8)           0         
_________________________________________________________________
activation_5 (Activation)    (None, 5, 5, 8)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 200)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 27)                5427      
_________________________________________________________________
activation_6 (Activation)    (None, 27)                0         
=================================================================
Total params: 12,043.0
Trainable params: 12,043.0
Non-trainable params: 0.0
_________________________________________________________________
Train on 54931 samples, validate on 6104 samples
Epoch 1/25
54931/54931 [==============================] - 93s - loss: 1.2582 - acc: 0.6441 - val_loss: 0.7163 - val_acc: 0.7926
Epoch 2/25
54931/54931 [==============================] - 92s - loss: 0.5977 - acc: 0.8274 - val_loss: 0.5304 - val_acc: 0.8380
Epoch 3/25
54931/54931 [==============================] - 92s - loss: 0.4665 - acc: 0.8634 - val_loss: 0.4430 - val_acc: 0.8706
Epoch 4/25
54931/54931 [==============================] - 92s - loss: 0.3971 - acc: 0.8831 - val_loss: 0.3813 - val_acc: 0.8897
Epoch 5/25
54931/54931 [==============================] - 94s - loss: 0.3564 - acc: 0.8949 - val_loss: 0.3602 - val_acc: 0.8986
Epoch 6/25
54931/54931 [==============================] - 93s - loss: 0.3256 - acc: 0.9034 - val_loss: 0.3456 - val_acc: 0.8932
Epoch 7/25
54931/54931 [==============================] - 93s - loss: 0.3025 - acc: 0.9106 - val_loss: 0.3235 - val_acc: 0.9007
Epoch 8/25
54931/54931 [==============================] - 93s - loss: 0.2834 - acc: 0.9149 - val_loss: 0.3168 - val_acc: 0.9081
Epoch 9/25
54931/54931 [==============================] - 93s - loss: 0.2686 - acc: 0.9194 - val_loss: 0.2940 - val_acc: 0.9158
Epoch 10/25
54931/54931 [==============================] - 92s - loss: 0.2523 - acc: 0.9240 - val_loss: 0.2801 - val_acc: 0.9155
Epoch 11/25
54931/54931 [==============================] - 92s - loss: 0.2404 - acc: 0.9264 - val_loss: 0.2585 - val_acc: 0.9238
Epoch 12/25
54931/54931 [==============================] - 92s - loss: 0.2260 - acc: 0.9315 - val_loss: 0.2557 - val_acc: 0.9256
Epoch 13/25
54931/54931 [==============================] - 92s - loss: 0.2152 - acc: 0.9342 - val_loss: 0.2364 - val_acc: 0.9261
Epoch 14/25
54931/54931 [==============================] - 91s - loss: 0.2070 - acc: 0.9368 - val_loss: 0.2432 - val_acc: 0.9240
Epoch 15/25
54931/54931 [==============================] - 92s - loss: 0.1931 - acc: 0.9421 - val_loss: 0.2214 - val_acc: 0.9307
Epoch 16/25
54931/54931 [==============================] - 92s - loss: 0.1896 - acc: 0.9415 - val_loss: 0.2368 - val_acc: 0.9278
Epoch 17/25
54931/54931 [==============================] - 93s - loss: 0.1793 - acc: 0.9459 - val_loss: 0.2121 - val_acc: 0.9359
Epoch 18/25
54931/54931 [==============================] - 92s - loss: 0.1722 - acc: 0.9478 - val_loss: 0.2035 - val_acc: 0.9376
Epoch 19/25
54931/54931 [==============================] - 92s - loss: 0.1624 - acc: 0.9499 - val_loss: 0.2319 - val_acc: 0.9300
Epoch 20/25
54931/54931 [==============================] - 93s - loss: 0.1600 - acc: 0.9507 - val_loss: 0.2114 - val_acc: 0.9402
Epoch 21/25
54931/54931 [==============================] - 92s - loss: 0.1524 - acc: 0.9532 - val_loss: 0.2109 - val_acc: 0.9379
Epoch 22/25
54931/54931 [==============================] - 95s - loss: 0.1490 - acc: 0.9533 - val_loss: 0.1925 - val_acc: 0.9423
Epoch 23/25
54931/54931 [==============================] - 93s - loss: 0.1407 - acc: 0.9570 - val_loss: 0.1940 - val_acc: 0.9412
Epoch 24/25
54931/54931 [==============================] - 93s - loss: 0.1355 - acc: 0.9587 - val_loss: 0.1831 - val_acc: 0.9451
Epoch 25/25
54931/54931 [==============================] - 93s - loss: 0.1304 - acc: 0.9597 - val_loss: 0.1886 - val_acc: 0.9436
Saved model to disk
